LIMA - Libre Multilingual Analyzer

LIMA is mutliplatform. It has been developed under GNU/Linux and recently 
compiled and run under MS Windows. Its installation procedure under Linux
is described bellow. Installation instructions under Windows are still to be 
written.

The various modules (lima_*) have different purposes:

 * lima_common
    contains tools shared by all modules (eg. factories)
 * lima_linguisticprocessing
    LIMA linguistic analyser
 * lima_linguisticdata
    linguistic ressources used in LIMA

== Install ==

Build dependencies: cmake, c++ (tested with gcc), gawk, libraries and 
development packages for : boost , Qt4, Qwt, enchant (optional, for  
orthographic correction), qhttpserver (optional, for lima http/json API).

Under Ubuntu, most of these dependencies are installed with the following 
packages:
$ sudo apt-get install gawk cmake libqtcore4 libqtgui4 libqt4-network \
libqwt-dev build-essential libqt4-dev qt4-dev-tools libboost-all-dev \
libenchant-dev 

Under Magia, most of these dependencies are installed with the following 
packages:
$ sudo urpmi cmake, lib64qwt-devel, (to be completed)

qhttpserver can be downloaded and installed from 
https://github.com/aymara/qhttpserver

As we were not able to find a Free part of speech tagged English corpus, LIMA 
depends for analyzing English on freely available but not free data that you 
will have to download and prepare yourself. This data is an extract of the Peen 
treebank corpus available for fair use in the NLTK data. To install, please 
refer to http://nltk.org/data.html. Under Ubuntu this can be  done like that:
$ sudo apt-get  install python-nltk
$ python
>>> import nltk
>>> nltk.download()
d dependency_treebank

Then prepare the data for use with LIMA by running the following commands:

$ cd $HOME/nltk_data/corpora/dependency_treebank
$ cat wsj_*.dp | grep -v "^$" > nltk-ptb.dp

You need to set up a few environment variables. For this purpose, you can 
source the setenv-lima.sh script from the root of the repository please check 
values before):
$ source ./setenv-lima.sh

Alternatively, you can define them manually:

LIMA_DIST             binaries and libraries
LIMA_EXTERNALS        dependencies
LIMA_RESOURCES        any kind of ressources (including training data)
LIMA_CONF             configuration folder
LINGUISTIC_DATA_ROOT  path to the lima_linguisticdata project root
NLTK_PTB_DP_FILE      path to the Penn treebank extract from NLTK (see below)

Then set PATH and LD_LIBRARY_PATH:
export PATH=$LIMA_DIST/bin:$LIMA_EXTERNALS/bin:$PATH
export LD_LIBRARY_PATH=$LIMA_EXTERNALS/lib:$LIMA_DIST/lib

Finally, from the LIMA repository root, run:
 $ ./gbuild.sh

== Build troubleshoutings

* If you use your own compiled boost libraries alongside system boost libraries 
AND cmake fails on lima_linguisticprocessings indicating it found your boost 
version headers but it uses the system libraries, add the following definition 
at the beginning of the root CMakeLists.txt of each subproject : 
set(Boost_NO_SYSTEM_PATHS ON)
